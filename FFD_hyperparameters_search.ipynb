{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../SPIE2019_COURSE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "import gc\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import SimpleITK as sitk\n",
    "import registration_gui as rgui\n",
    "import utilities \n",
    "from downloaddata import fetch_data as fdata\n",
    "from ipywidgets import interact, fixed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data\n",
    "source_path = './data'\n",
    "# Directory of images inside source_path\n",
    "images_dir = '/images'\n",
    "# Directory of masks inside source_path\n",
    "mask_dir = '/masks'\n",
    "# Directory of landmarks inside source_path\n",
    "landmarks_dir = '/landmarks'\n",
    "\n",
    "# Path to the results\n",
    "results_path = './results' \n",
    "# Directory of the images registration results\n",
    "registration_results_dir = '/registration' \n",
    "# Directory of the hyperparameters seach results\n",
    "hp_search_results_dir = '/hp_results'\n",
    "\n",
    "# Identifier of the current param grids\n",
    "params_grid_id = '02'\n",
    "\n",
    "# Number of patients\n",
    "n_patients = 6\n",
    "patient_ids = range(1, n_patients + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of the hyperparameters search\n",
    "params_grid = {\n",
    "    'grid_physical_spacing': [10.0, 20.0, 30.0],\n",
    "    'similarity_function': ['mean_squares', 'mattes_mutual_information', 'correlation', 'joint_histogram_mutual_information'],\n",
    "    'optimizer': ['lbfgs2'],\n",
    "    'max_optimizer_iterations': [5000],\n",
    "    'scale_parameter_and_smoothing_sigma_max_power': [1, 2, 3],\n",
    "    'interpolator': ['linear', 'bspline']\n",
    "}\n",
    "\n",
    "# Computing a list with all combinations and shuffle it\n",
    "grid = list(ParameterGrid(params_grid))\n",
    "shuffle(grid)\n",
    "        \n",
    "print('Total combinations: {}'.format(len(grid)))\n",
    "\n",
    "time_per_config = 0.2\n",
    "est_time = len(grid) * time_per_config * 6\n",
    "print('Estimated time {:.2f}h'.format(est_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If the kernel deads or the laptop runs out of memory, load the already computed combinations and\n",
    "remove it from the param_grid.\n",
    "\n",
    "'''\n",
    "# Load the previously computed parameters\n",
    "files_to_load = glob.glob(os.path.join(results_path + hp_search_results_dir, params_grid_id) + '/*.json')\n",
    "\n",
    "data = []\n",
    "for file in files_to_load:\n",
    "    with open(file, 'r') as fp:\n",
    "        data.append(eval(json.load(fp)))\n",
    "        \n",
    "df_data = pd.DataFrame(data)\n",
    "\n",
    "params_ls = [row['params'] for idx, row in df_data.iterrows()]\n",
    "\n",
    "# Get the parameters combination that have not been computed yet\n",
    "grid = [x for x in grid if x not in params_ls]\n",
    "\n",
    "del df_data, params_ls\n",
    "gc.collect()\n",
    "\n",
    "print('Total combinations: {}'.format(len(grid)))\n",
    "\n",
    "time_per_config = 0.2\n",
    "est_time = len(grid) * time_per_config * 6\n",
    "print('Estimated time {:.2f}h'.format(est_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(path_to_save, file_name, results):\n",
    "    '''\n",
    "    Save in JSON format the results for every parameters combination\n",
    "    \n",
    "    Args:\n",
    "    - path_to_save (string): Path to save the JSON file.\n",
    "    - file_name (string): Name of the JSON file.\n",
    "    - results (dict): Dictionary with the results.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    '''\n",
    "    # Check if the directory exists, if not create one\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    # Save resutls as JSON file\n",
    "    with open(os.path.join(path_to_save, file_name), 'w') as fp:\n",
    "        json.dump(str(results), fp)\n",
    "        \n",
    "    gc.collect()\n",
    "    return None\n",
    "\n",
    "def save_transform(path_to_save, file_name, transform):\n",
    "    '''\n",
    "    Save in TFM format the final transform\n",
    "    \n",
    "    Args:\n",
    "    - path_to_save (string): Path to save the TFM file.\n",
    "    - file_name (string): Name of the TFM file.\n",
    "    - transform (SimpleITK.SimpleITK.Transform): SimpleITK transform to save.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    '''\n",
    "    # Check if the directory exists, if not create one\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    # Save tranformation as TFM file\n",
    "    sitk.WriteTransform(transform, os.path.join(path_to_save, file_name + '.tfm'))\n",
    "        \n",
    "    gc.collect()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_callback_ffd(filter):\n",
    "    # Define a simple callback which allows us to monitor registration progress.\n",
    "    print('\\rRegistration progress -> {0:.2f}'.format(filter.GetMetricValue()), end='')\n",
    "\n",
    "def free_form_deformation_registration(images, masks, params):\n",
    "    '''\n",
    "    Computes the free form deformation algorithm for the registration of the images.\n",
    "    \n",
    "    Args:\n",
    "    - images (list(SimpleITK.Image)): Images to feed the registration algorithm.\n",
    "    - masks (list(SimpleITK.Image)): Masks to feed the registration algorithm.\n",
    "    - params (dict): Dictionary with the parameters to use in the algorithm.\n",
    "    \n",
    "    Returns:\n",
    "    - final_transformation (SimpleITK.Transform)\n",
    "    - stop_condition (str)\n",
    "    '''\n",
    "    fixed_index = 0\n",
    "    moving_index = 1\n",
    "\n",
    "    fixed_image = images[fixed_index]\n",
    "    fixed_image_mask = masks[fixed_index] == 1\n",
    "\n",
    "    moving_image = images[moving_index]\n",
    "    moving_image_mask = masks[moving_index] == 1\n",
    "    \n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    \n",
    "    # Determine the number of BSpline control points using the physical \n",
    "    # spacing we want for the finest resolution control grid. \n",
    "    grid_physical_spacing = [params['grid_physical_spacing'], params['grid_physical_spacing'], params['grid_physical_spacing']] # A control point every grid_physical_spacingmm\n",
    "    image_physical_size = [size*spacing for size,spacing in zip(fixed_image.GetSize(), fixed_image.GetSpacing())]\n",
    "    mesh_size = [int(image_size/grid_spacing + 0.5) \\\n",
    "                 for image_size,grid_spacing in zip(image_physical_size,grid_physical_spacing)]\n",
    "    # The starting mesh size will be 1/4 of the original, it will be refined by \n",
    "    # the multi-resolution framework.\n",
    "    mesh_size = [int(sz/4 + 0.5) for sz in mesh_size]\n",
    "\n",
    "    initial_transform = sitk.BSplineTransformInitializer(image1 = fixed_image, \n",
    "                                                         transformDomainMeshSize = mesh_size, order=3)    \n",
    "    # Instead of the standard SetInitialTransform we use the BSpline specific method which also\n",
    "    # accepts the scaleFactors parameter to refine the BSpline mesh. In this case we start with \n",
    "    # the given mesh_size at the highest pyramid level then we double it in the next lower level and\n",
    "    # in the full resolution image we use a mesh that is four times the original size.\n",
    "    registration_method.SetInitialTransformAsBSpline(initial_transform,\n",
    "                                                     inPlace=False,\n",
    "                                                     scaleFactors=[1,2,4])\n",
    "\n",
    "    # Selecting similarity fuction\n",
    "    if params['similarity_function'] == 'mean_squares':\n",
    "        registration_method.SetMetricAsMeanSquares()\n",
    "    elif params['similarity_function'] == 'mattes_mutual_information':\n",
    "        registration_method.SetMetricAsMattesMutualInformation()\n",
    "    elif params['similarity_function'] == 'correlation':\n",
    "        registration_method.SetMetricAsCorrelation()\n",
    "    elif params['similarity_function'] == 'ants_neighborhood_correlation':\n",
    "        registration_method.SetMetricAsANTSNeighborhoodCorrelation(radius=1)\n",
    "    elif params['similarity_function'] == 'joint_histogram_mutual_information':\n",
    "        registration_method.SetMetricAsJointHistogramMutualInformation()\n",
    "    else:\n",
    "        raise ValueError('Invalid similarity function')\n",
    "        \n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "    registration_method.SetMetricFixedMask(fixed_image_mask)\n",
    "\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[2 ** i for i in range(params['scale_parameter_and_smoothing_sigma_max_power'] - 1, -1, -1)])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2 ** i for i in range(params['scale_parameter_and_smoothing_sigma_max_power'] - 2, -1, -1)] + [0])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Selecting interpolator\n",
    "    if params['interpolator'] == 'linear':\n",
    "        registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "    elif params['interpolator'] == 'bspline':\n",
    "        registration_method.SetInterpolator(sitk.sitkBSpline)\n",
    "    else:\n",
    "        raise ValueError('Invalid interpolator')\n",
    "    \n",
    "    # Selecting optimizer\n",
    "    if params['optimizer'] == 'amoeba':\n",
    "        registration_method.SetOptimizerAsAmoeba(simplexDelta=0.1, numberOfIterations=params['max_optimizer_iterations'])\n",
    "    elif params['optimizer'] == 'one_plus_one':\n",
    "        registration_method.SetOptimizerAsOnePlusOneEvolutionary(numberOfIterations=params['max_optimizer_iterations'])\n",
    "    elif params['optimizer'] == 'powell':\n",
    "        registration_method.SetOptimizerAsPowell(numberOfIterations=params['max_optimizer_iterations'])\n",
    "    elif params['optimizer'] == 'step_gradient_descent':\n",
    "        registration_method.SetOptimizerAsRegularStepGradientDescent(learningRate=0.1, minStep=0.1, numberOfIterations=params['max_optimizer_iterations'])\n",
    "    elif params['optimizer'] == 'gradient_line_search':\n",
    "        registration_method.SetOptimizerAsConjugateGradientLineSearch(learningRate=0.01, numberOfIterations=params['max_optimizer_iterations'])\n",
    "    elif params['optimizer'] == 'gradient_descent':\n",
    "        registration_method.SetOptimizerAsGradientDescent(learningRate=0.01, numberOfIterations=params['max_optimizer_iterations'])\n",
    "    elif params['optimizer'] == 'dradient_descent_line_search':\n",
    "        registration_method.SetOptimizerAsGradientDescentLineSearch(learningRate=0.01, numberOfIterations=params['max_optimizer_iterations'])\n",
    "    elif params['optimizer'] == 'lbfgs2':\n",
    "        registration_method.SetOptimizerAsLBFGS2(numberOfIterations=params['max_optimizer_iterations'])\n",
    "    else:\n",
    "        raise ValueError('Invalid optimization function')\n",
    "        \n",
    "    registration_method.AddCommand(sitk.sitkIterationEvent, lambda: iteration_callback_ffd(registration_method))\n",
    "\n",
    "    final_transformation = registration_method.Execute(fixed_image, moving_image)\n",
    "    stop_condition = registration_method.GetOptimizerStopConditionDescription()\n",
    "    print('\\nOptimizer\\'s stopping condition, {0}'.format(stop_condition))\n",
    "\n",
    "    return final_transformation, stop_condition\n",
    "\n",
    "\n",
    "def registration(original_images_path, original_masks_path, transformed_files_path, patient_id, params):\n",
    "    '''\n",
    "    Load the images and compute the registration of the images for each patient. The available methods are\n",
    "    free form deformation and demons based registration algorithms.\n",
    "    \n",
    "    Args:\n",
    "    - original_images_path (str): Path to the original images.\n",
    "    - original_masks_path (str): Path to the original masks.\n",
    "    - transformed_files_path (str): Path to save the transformed files.\n",
    "    - patient_id (int): Id of the patient.\n",
    "    - params (dict): Dictionary with the parameters to use in the algorithm.\n",
    "    \n",
    "    Returns:\n",
    "    - stop_condition (str)\n",
    "    '''\n",
    "    # Load images and masks\n",
    "    images = []\n",
    "    masks = []\n",
    "    for i in [0, 5]:\n",
    "        image_file_name = original_images_path + '/0' + str(patient_id) + '/{}0.mhd'.format(i)\n",
    "        mask_file_name = original_masks_path + '/0' + str(patient_id) + '/{}0.mhd'.format(i)\n",
    "        \n",
    "        images.append(sitk.ReadImage(image_file_name, sitk.sitkFloat32)) \n",
    "        masks.append(sitk.ReadImage(mask_file_name))\n",
    "    \n",
    "    # Compute the registration\n",
    "    final_transform, stop_condition = free_form_deformation_registration(images, masks, params)\n",
    "        \n",
    "    # Save the final transform\n",
    "    save_transform(transformed_files_path + '/0' + str(patient_id), 'final_transform', final_transform)\n",
    "    gc.collect()\n",
    "    return stop_condition\n",
    "\n",
    "def evaluate_registration(images_files_path, mask_files_path, landmark_files_path, transformed_files_path, patient_id):\n",
    "    '''\n",
    "    Evaluates the performance of the registration computing different metrics.\n",
    "    \n",
    "    Args:\n",
    "    - images_files_path (str): Path to the image files.\n",
    "    - mask_files_path (str): Path to the mask files.\n",
    "    - landmark_files_path (str): Path to the landmarks files.\n",
    "    - transformed_files_path (str): Path to the transformed files.\n",
    "    - patient_id (int): Id of the patient.\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): Dictionary with all the evaluation metrics.\n",
    "    '''\n",
    "    \n",
    "    # Load images, masks and landmarks\n",
    "    images = []\n",
    "    masks = []\n",
    "    landmarks = []\n",
    "    for i in [0, 5]:\n",
    "        image_file_name = images_files_path + '/0' + str(patient_id) + '/{}0.mhd'.format(i)\n",
    "        mask_file_name = mask_files_path + '/0' + str(patient_id) + '/{}0.mhd'.format(i)\n",
    "        landmarks_file_name = landmark_files_path + '/0' + str(patient_id) + '/{}0.pts.txt'.format(i)\n",
    "        images.append(sitk.ReadImage(image_file_name, sitk.sitkFloat32)) \n",
    "        masks.append(sitk.ReadImage(mask_file_name))\n",
    "        landmarks.append(utilities.read_POPI_points(landmarks_file_name))\n",
    "    \n",
    "    # Load transformation\n",
    "    transformation = sitk.ReadTransform(transformed_files_path + '/0' + str(patient_id) + '/final_transform.tfm')\n",
    "    \n",
    "    # Create dictionary to store all the relevant information\n",
    "    results = {}\n",
    "    \n",
    "    # Define fixed and moving index\n",
    "    fixed_index = 0\n",
    "    moving_index = 1\n",
    "    \n",
    "    \n",
    "    # Compute the evaluation criteria with landmarks\n",
    "    final_TRE = utilities.target_registration_errors(transformation, landmarks[fixed_index], landmarks[moving_index])\n",
    "\n",
    "    # Save TRE\n",
    "    results['TRE'] = final_TRE\n",
    "    \n",
    "    # Transfer the segmentation via the estimated transformation. \n",
    "    # Nearest Neighbor interpolation so we don't introduce new labels.\n",
    "    transformed_labels = sitk.Resample(masks[moving_index],\n",
    "                                       images[fixed_index],\n",
    "                                       transformation, \n",
    "                                       sitk.sitkNearestNeighbor,\n",
    "                                       0.0, \n",
    "                                       masks[moving_index].GetPixelID())\n",
    "    \n",
    "    # Specify reference masks\n",
    "    reference_segmentation = masks[fixed_index]\n",
    "    # Segmentations after registration ensure that it is the correct label \n",
    "    seg = transformed_labels == 1\n",
    " \n",
    "    # Compute the evaluation criteria with masks\n",
    "\n",
    "    # Note that for the overlap measures filter, because we are dealing with a single label we \n",
    "    # use the combined, all labels, evaluation measures without passing a specific label to the methods.\n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    hausdorff_distance_filter = sitk.HausdorffDistanceImageFilter()\n",
    "\n",
    "    # Use the absolute values of the distance map to compute the surface distances (distance map sign, outside or inside \n",
    "    # relationship, is irrelevant)\n",
    "    label = 1\n",
    "    reference_distance_map = sitk.Abs(sitk.SignedMaurerDistanceMap(reference_segmentation, squaredDistance=False))\n",
    "    reference_surface = sitk.LabelContour(reference_segmentation)\n",
    "    statistics_image_filter = sitk.StatisticsImageFilter()\n",
    "    \n",
    "    # Get the number of pixels in the reference surface by counting all pixels that are 1.\n",
    "    statistics_image_filter.Execute(reference_surface)\n",
    "    num_reference_surface_pixels = int(statistics_image_filter.GetSum()) \n",
    "\n",
    "    # Overlap measures\n",
    "    overlap_measures_filter.Execute(reference_segmentation, seg)\n",
    "    results['JI'] = overlap_measures_filter.GetJaccardCoefficient()\n",
    "    results['DC'] = overlap_measures_filter.GetDiceCoefficient()\n",
    "    results['VS'] = overlap_measures_filter.GetVolumeSimilarity()\n",
    "     \n",
    "    # Hausdorff distance\n",
    "    hausdorff_distance_filter.Execute(reference_segmentation, seg)\n",
    "    results['HD'] = hausdorff_distance_filter.GetHausdorffDistance()\n",
    "    \n",
    "    # Symmetric surface distance measures\n",
    "    segmented_distance_map = sitk.Abs(sitk.SignedMaurerDistanceMap(seg, squaredDistance=False))\n",
    "    segmented_surface = sitk.LabelContour(seg)\n",
    "        \n",
    "    # Multiply the binary surface segmentations with the distance maps. The resulting distance\n",
    "    # maps contain non-zero values only on the surface (they can also contain zero on the surface)\n",
    "    seg2ref_distance_map = reference_distance_map*sitk.Cast(segmented_surface, sitk.sitkFloat32)\n",
    "    ref2seg_distance_map = segmented_distance_map*sitk.Cast(reference_surface, sitk.sitkFloat32)\n",
    "        \n",
    "    # Get the number of pixels in the segmented surface by counting all pixels that are 1.\n",
    "    statistics_image_filter.Execute(segmented_surface)\n",
    "    num_segmented_surface_pixels = int(statistics_image_filter.GetSum())\n",
    "    \n",
    "    # Get all non-zero distances and then add zero distances if required.\n",
    "    seg2ref_distance_map_arr = sitk.GetArrayViewFromImage(seg2ref_distance_map)\n",
    "    seg2ref_distances = list(seg2ref_distance_map_arr[seg2ref_distance_map_arr!=0]) \n",
    "    seg2ref_distances = seg2ref_distances + \\\n",
    "                        list(np.zeros(num_segmented_surface_pixels - len(seg2ref_distances)))\n",
    "    ref2seg_distance_map_arr = sitk.GetArrayViewFromImage(ref2seg_distance_map)\n",
    "    ref2seg_distances = list(ref2seg_distance_map_arr[ref2seg_distance_map_arr!=0]) \n",
    "    ref2seg_distances = ref2seg_distances + \\\n",
    "                        list(np.zeros(num_reference_surface_pixels - len(ref2seg_distances)))\n",
    "        \n",
    "    all_surface_distances = seg2ref_distances + ref2seg_distances\n",
    "    \n",
    "    results['SD'] = all_surface_distances\n",
    "       \n",
    "    results['R'] = 0.2*np.mean(results['TRE'])+0.3*np.mean(results['HD'])+0.5*100*np.abs(results['VS'])\n",
    "    return results\n",
    "\n",
    "def statistical_info_from_results(results):\n",
    "    '''\n",
    "    Compute some statistical information from the results of all patients\n",
    "    \n",
    "    Args:\n",
    "    - results (dict): Dictionary with the all the results.\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): Dictionary with the all the results and the statistical info.\n",
    "    '''\n",
    "    JI_ls = [results['patient_0' + str(patient_id)]['JI'] for patient_id in patient_ids]\n",
    "    results['JI_mean'] = np.mean(JI_ls) \n",
    "    results['JI_median'] = np.median(JI_ls) \n",
    "    results['JI_std'] = np.std(JI_ls) \n",
    "    \n",
    "    DC_ls = [results['patient_0' + str(patient_id)]['DC'] for patient_id in patient_ids]\n",
    "    results['DC_mean'] = np.mean(DC_ls) \n",
    "    results['DC_median'] = np.median(DC_ls) \n",
    "    results['DC_std'] = np.std(DC_ls) \n",
    "    \n",
    "    SD_ls = [np.mean(results['patient_0' + str(patient_id)]['SD']) for patient_id in patient_ids]\n",
    "    results['SD_mean'] = np.mean(SD_ls) \n",
    "    results['SD_median'] = np.median(SD_ls) \n",
    "    results['SD_std'] = np.std(SD_ls) \n",
    "    \n",
    "    TRE_ls = [np.mean(results['patient_0' + str(patient_id)]['TRE']) for patient_id in patient_ids]\n",
    "    results['TRE_mean'] = np.mean(TRE_ls) \n",
    "    results['TRE_median'] = np.median(TRE_ls) \n",
    "    results['TRE_std'] = np.std(TRE_ls) \n",
    "    \n",
    "    HD_ls = [results['patient_0' + str(patient_id)]['HD'] for patient_id in patient_ids]\n",
    "    results['HD_mean'] = np.mean(HD_ls) \n",
    "    results['HD_median'] = np.median(HD_ls) \n",
    "    results['HD_std'] = np.std(HD_ls) \n",
    "    \n",
    "    VS_ls = [results['patient_0' + str(patient_id)]['VS'] for patient_id in patient_ids]\n",
    "    results['VS_mean'] = np.mean(VS_ls) \n",
    "    results['VS_median'] = np.median(VS_ls) \n",
    "    results['VS_std'] = np.std(VS_ls) \n",
    "    \n",
    "    R_ls = [results['patient_0' + str(patient_id)]['R'] for patient_id in patient_ids]\n",
    "    results['R_mean'] = np.mean(R_ls) \n",
    "    results['R_median'] = np.median(R_ls) \n",
    "    results['R_std'] = np.std(R_ls) \n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output on the terminal\n",
    "#sys.stdout = open('/dev/stdout', 'w')\n",
    "\n",
    "for idx, params in enumerate(grid):    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    # Create an unique id for the parameters combination\n",
    "    params_id = uuid.uuid4()\n",
    "    print('parameters {}, id: {}, params: {}'.format(idx, params_id, params))\n",
    "    \n",
    "    # Save all the important data in the results dict\n",
    "    results = {}\n",
    "    results['id'] = str(params_id)\n",
    "    results['params'] = params\n",
    "    \n",
    "    # Compute the registration for each patient\n",
    "    for patient_id in patient_ids:\n",
    "        print('params_id: {}, patient: {}'.format(params_id, patient_id))\n",
    "        \n",
    "        stop_condition = registration(source_path + images_dir, \n",
    "                                      source_path + mask_dir, \n",
    "                                      os.path.join(results_path + registration_results_dir, params_grid_id, str(params_id)),\n",
    "                                      patient_id, params)\n",
    "        \n",
    "        registration_evaluation_results = evaluate_registration(source_path + images_dir,\n",
    "                                                                source_path + mask_dir, \n",
    "                                                                source_path + landmarks_dir, \n",
    "                                                                os.path.join(results_path + registration_results_dir, params_grid_id, str(params_id)),\n",
    "                                                                patient_id)\n",
    "\n",
    "        # Store the results for each patient\n",
    "        results['patient_0' + str(patient_id) + '_stop_cond'] = stop_condition\n",
    "        results['patient_0' + str(patient_id)] = registration_evaluation_results\n",
    "        gc.collect()\n",
    "        \n",
    "    # Compute some statistical information from the results\n",
    "    results = statistical_info_from_results(results)\n",
    "    \n",
    "    t_end = time.time()\n",
    "    results['computation_time_min'] = (t_end - t_start) / 60\n",
    "    \n",
    "    # Save the results of this parameters combination to a file\n",
    "    path_to_save = os.path.join(results_path + hp_search_results_dir, params_grid_id)\n",
    "    file_name = str(params_id) + '.json'\n",
    "    save_results(path_to_save, file_name, results)\n",
    "    gc.collect()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
